{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fbfca37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-5.4.0-py2.py3-none-any.whl (25.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.3 MB 410 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from plotly) (1.15.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly) (7.0.0)\n",
      "Installing collected packages: plotly\n",
      "Successfully installed plotly-5.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5d329d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-366e02ddeb3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a14141db",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e4dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f304a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=10\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b7fedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding ##\n",
    "class Encoder(keras.Model):\n",
    "    def __init__(self,n_layers=2,latent_features=2,hidden_featrues=64):\n",
    "        super().__init__()\n",
    "        self.latent_features=latent_features\n",
    "        # First Layer\n",
    "        self.conv_0=keras.layers.Conv2D(hidden_featrues, kernel_size=3, activation=\"relu\",padding='same')\n",
    "        self.dropout_0=keras.layers.Dropout(0.2)\n",
    "        # Middle Layers\n",
    "        self.convs=[keras.layers.Conv2D(hidden_featrues, kernel_size=3, activation=\"relu\",padding='same') for _ in range(n_layers)]\n",
    "        self.mxpools = [keras.layers.MaxPooling2D(pool_size=2) for _ in range(n_layers)]\n",
    "        self.dropouts = [keras.layers.Dropout(0.2) for _ in range(n_layers)]\n",
    "        # Integration Layer(Output Layer)\n",
    "        WIDTH=2\n",
    "        self.gap=keras.layers.AveragePooling2D(pool_size=WIDTH,)\n",
    "        self.flatten=keras.layers.Flatten()\n",
    "        self.dense=keras.layers.Dense(latent_features)\n",
    "      \n",
    "    def call(self,x):\n",
    "        x=self.dropout_0(self.conv_0(x))\n",
    "        for conv,mxp,drp in zip(self.convs,self.mxpools,self.dropouts):\n",
    "            x=drp(mxp(conv(x)))\n",
    "        x=self.gap(x)\n",
    "        x=self.flatten(x)\n",
    "        y=self.dense(x)\n",
    "        return y\n",
    "\n",
    "## Special Layers ##\n",
    "def cos_sim(q,s):\n",
    "    query=tf.math.l2_normalize(q, axis=-1)\n",
    "    support=tf.math.l2_normalize(s, axis=-1)\n",
    "    cosine=tf.matmul(query,support,transpose_b=True)\n",
    "    return cosine\n",
    "class CosineLayer(keras.layers.Layer):\n",
    "    def __init__(self, out_features=10):\n",
    "        super().__init__()\n",
    "        self.out_features = out_features\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(self.out_features,input_shape[-1]),\n",
    "                               initializer='glorot_uniform',\n",
    "                               trainable=True)\n",
    "    def call(self, inputs):\n",
    "        return cos_sim(inputs,self.w)\n",
    "\n",
    "## Main Model ##\n",
    "class ClassModel(keras.Model):\n",
    "    def __init__(self,encoder,out_features=10,mode=\"dense\"):\n",
    "        super().__init__()\n",
    "        self.encoder=encoder\n",
    "        self.mode=mode\n",
    "        latent_features=encoder.latent_features\n",
    "        \n",
    "        \n",
    "        if self.mode==\"dense\":\n",
    "            self.output_layer=keras.layers.Dense(out_features,use_bias=False)\n",
    "            self.out_func=keras.layers.Softmax()\n",
    "        else:\n",
    "            self.output_layer=CosineLayer(out_features)\n",
    "        \n",
    "    def call(self,x,training=False):\n",
    "        latent=self.encoder(x)\n",
    "        if self.mode==\"dense\":\n",
    "            y=self.out_func(self.output_layer(latent))\n",
    "            return y\n",
    "        else:\n",
    "            cosine=self.output_layer(latent)\n",
    "            return cosine\n",
    "\n",
    "## Loss function ##\n",
    "class FocalLoss():\n",
    "    def __init__(self, gamma=3, eps=1e-10):\n",
    "        self.gamma = gamma\n",
    "        self.eps = tf.constant(eps)\n",
    "        self.softmax =keras.layers.Softmax()\n",
    "        self.cce=keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "        self.__name__=\"loss\"\n",
    "    def __call__(self,y_true, y_pred): \n",
    "        logp = self.cce(y_true,self.softmax(y_pred+self.eps))\n",
    "        p = tf.exp(-logp)\n",
    "        loss = (tf.constant(1.) - p) ** self.gamma * logp\n",
    "        return tf.reduce_mean(loss, axis=-1)\n",
    "    \n",
    "class AddMarginLoss():\n",
    "    def __init__(self,s=5,m=0.3,gamma=3):\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.lossfn=FocalLoss(gamma)\n",
    "        self.__name__=\"loss\"\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        cosine=y_pred\n",
    "        phi = cosine - self.m\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        arc = (y_true * phi) + ((1.0 - y_true) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n",
    "        arc *= self.s\n",
    "        return self.lossfn(y_true,arc)\n",
    "    \n",
    "class ArcMarginLoss():\n",
    "    def __init__(self,s=32,m=0.3,easy_margin=False, eps=1e-6):\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.eps=tf.constant(eps)# This is very, very, very important\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "        \n",
    "        self.lossfn=FocalLoss()\n",
    "        self.__name__=\"loss\"\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        cosine=y_pred\n",
    "        \n",
    "        sine = tf.sqrt(tf.constant(1.) - tf.pow(cosine, 2) + self.eps)\n",
    "        \n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where((cosine - self.th) > 0, phi, cosine - self.mm)\n",
    "        \n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        arc = (y_true * phi) + ((1.0 - y_true) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n",
    "        arc *= self.s\n",
    "        return self.lossfn(y_true,arc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a1a3158",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=Encoder(n_layers=2,latent_features=2,hidden_featrues=64)\n",
    "model=ClassModel(enc,out_features=10,mode=\"arc\")\n",
    "\n",
    "loss_fn=ArcMarginLoss(s=5,m=0.4,easy_margin=False)\n",
    "opt=keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=loss_fn, optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7043eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in train_loader:\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87aad277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.GradientTape() as tape:\n",
    "#     l,w=model(x)\n",
    "#     loss=loss_fn(y,(l,w))\n",
    "# gradient =tape.gradient(loss,model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "290414bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recording Callbacks\n",
    "\n",
    "class LogLatent(keras.callbacks.Callback):\n",
    "    def __init__(self,encoder,test_x,test_y,skip_iters=100):\n",
    "        self.df=self.df=pd.DataFrame()\n",
    "        self.encoder=encoder\n",
    "        self.plt_x=test_x\n",
    "        self.plt_y=test_y\n",
    "        self.itr=0\n",
    "        self.skip_iters=skip_iters\n",
    "    def on_batch_end(self,batch, logs={}):\n",
    "        if self.itr%self.skip_iters==self.skip_iters-1:\n",
    "            latent=self.encoder(self.plt_x)\n",
    "            df_new=pd.DataFrame()\n",
    "            df_new[\"f1\"]=latent[:,0]\n",
    "            df_new[\"f2\"]=latent[:,1]\n",
    "            df_new[\"arc\"]=0.5\n",
    "            df_new[\"iterations\"]=np.repeat(self.itr,len(latent))\n",
    "\n",
    "            df_new[\"label\"]=self.plt_y\n",
    "            self.df=self.df.append(df_new)\n",
    "        self.itr+=1\n",
    "    def normalize(self):\n",
    "        # Normalize latent by maximum value\n",
    "        self.mx_norm=np.linalg.norm(self.df[[\"f1\",\"f2\"]].values,axis=1).max()\n",
    "        self.df[[\"f1\",'f2']]=self.df[[\"f1\",'f2']].apply(lambda x: x/self.mx_norm)\n",
    "\n",
    "        # Project latents into arc\n",
    "        df=self.df.copy()\n",
    "        norm=np.linalg.norm(df[[\"f1\",\"f2\"]].values,axis=1,keepdims=True)\n",
    "        df[[\"f1\",'f2']]=df[[\"f1\",'f2']].values/norm\n",
    "        df[\"arc\"]=df[\"arc\"].map({0.5:0.9},na_action=None)\n",
    "        \n",
    "        self.df=self.df.append(df)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b89dad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "plt_x,plt_y=x_test[:batch_size],y_test[:batch_size]\n",
    "lg=LogLatent(enc,plt_x,plt_y.argmax(-1))\n",
    "\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train,y_train)).cache().shuffle(len(x_train)//2).batch(batch_size)\n",
    "val_loader = tf.data.Dataset.from_tensor_slices((x_val,y_val)).cache().shuffle(len(x_val)//2).batch(batch_size*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ef803e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 5s 10ms/step - loss: 3.4314 - accuracy: 0.3085 - val_loss: 0.7100 - val_accuracy: 0.7554\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.7292 - accuracy: 0.7371 - val_loss: 0.5465 - val_accuracy: 0.8253\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5913 - accuracy: 0.8032 - val_loss: 0.4648 - val_accuracy: 0.8737\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5178 - accuracy: 0.8413 - val_loss: 0.4248 - val_accuracy: 0.8994\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4839 - accuracy: 0.8687 - val_loss: 0.4190 - val_accuracy: 0.9067\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4530 - accuracy: 0.8846 - val_loss: 0.3987 - val_accuracy: 0.9149\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4412 - accuracy: 0.8897 - val_loss: 0.3729 - val_accuracy: 0.9271\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4052 - accuracy: 0.9063 - val_loss: 0.3625 - val_accuracy: 0.9313\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4019 - accuracy: 0.9087 - val_loss: 0.3529 - val_accuracy: 0.9360\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4159 - accuracy: 0.9042 - val_loss: 0.3642 - val_accuracy: 0.9310\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.fit(train_loader, \n",
    "              epochs=epochs,\n",
    "              validation_data=val_loader,\n",
    "              callbacks=[lg])\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8304bb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3430 - accuracy: 0.9390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.343005508184433, 0.9390000104904175]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a0233f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d8c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=px.scatter(lg.df, x=\"f1\", y=\"f2\", animation_frame=\"iterations\", color=\"label\",opacity=lg.df.arc,\n",
    "                range_x=[-1.5,1.5],\n",
    "              range_y=[-1.5,1.5])\n",
    "fig.update_yaxes(\n",
    "    scaleanchor = \"x\",\n",
    "    scaleratio = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a87d0855",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"history/arc_tf.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdfd2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
