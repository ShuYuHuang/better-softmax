{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "025d7f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Using cached plotly-5.3.1-py2.py3-none-any.whl (23.9 MB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from plotly) (1.15.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly) (7.0.0)\n",
      "Installing collected packages: plotly\n",
      "Successfully installed plotly-5.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa086a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b6cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e377eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3bd8ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=10\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "520895a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(keras.Model):\n",
    "    def __init__(self,n_layers=2,latent_features=2,hidden_featrues=64):\n",
    "        super().__init__()\n",
    "        self.latent_features=latent_features\n",
    "        # First Layer\n",
    "        self.conv_0=keras.layers.Conv2D(hidden_featrues, kernel_size=3, activation=\"relu\",padding='same')\n",
    "        self.dropout_0=keras.layers.Dropout(0.2)\n",
    "        # Middle Layers\n",
    "        self.convs=[keras.layers.Conv2D(hidden_featrues, kernel_size=3, activation=\"relu\",padding='same') for _ in range(n_layers)]\n",
    "        self.mxpools = [keras.layers.MaxPooling2D(pool_size=2) for _ in range(n_layers)]\n",
    "        self.dropouts = [keras.layers.Dropout(0.2) for _ in range(n_layers)]\n",
    "        # Integration Layer(Output Layer)\n",
    "        WIDTH=2\n",
    "        self.gap=keras.layers.AveragePooling2D(pool_size=WIDTH,)\n",
    "        self.flatten=keras.layers.Flatten()\n",
    "        self.dense=keras.layers.Dense(latent_features)\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        x=self.dropout_0(self.conv_0(x))\n",
    "        for conv,mxp,drp in zip(self.convs,self.mxpools,self.dropouts):\n",
    "            x=drp(mxp(conv(x)))\n",
    "        x=self.gap(x)\n",
    "        x=self.flatten(x)\n",
    "        y=self.dense(x)\n",
    "        return y\n",
    "    \n",
    "class ClassModel(keras.Model):\n",
    "    def __init__(self,encoder,out_features=10,mode=\"dense\"):\n",
    "        super().__init__()\n",
    "        self.encoder=encoder\n",
    "        self.mode=mode\n",
    "        \n",
    "        self.out_weight=keras.layers.Dense(out_features,use_bias=False)\n",
    "        \n",
    "        if self.mode==\"dense\":\n",
    "            self.out_func=keras.layers.Softmax()\n",
    "#         if self.mode==\"cos\":\n",
    "#             self.out_func=AddMarginProduct(latent_features,out_features,s=s,m=m)\n",
    "#         if self.mode==\"arc\":\n",
    "#             self.out_func=ArcMarginProduct(latent_features,out_features,s=s,m=m,easy_margin=easy_margin)\n",
    "        \n",
    "        \n",
    "    def __call__(self,x,training=False):\n",
    "        latent=self.encoder(x)\n",
    "        y=self.out_func(self.out_weight(latent))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ae56b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=Encoder(n_layers=2,latent_features=2,hidden_featrues=64)\n",
    "model=ClassModel(enc,out_features=10,mode=\"dense\")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1e9b445",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recording Callbacks\n",
    "\n",
    "class LogLatent(keras.callbacks.Callback):\n",
    "    def __init__(self,encoder,test_x,test_y,skip_iters=100):\n",
    "        self.df=self.df=pd.DataFrame()\n",
    "        self.encoder=encoder\n",
    "        self.plt_x=test_x\n",
    "        self.plt_y=test_y\n",
    "        self.itr=0\n",
    "        self.skip_iters=skip_iters\n",
    "    def on_batch_end(self,batch, logs={}):\n",
    "        if self.itr%self.skip_iters==self.skip_iters-1:\n",
    "            latent=self.encoder(self.plt_x)\n",
    "            df_new=pd.DataFrame()\n",
    "            df_new[\"f1\"]=latent[:,0]\n",
    "            df_new[\"f2\"]=latent[:,1]\n",
    "            df_new[\"arc\"]=0.5\n",
    "            df_new[\"iterations\"]=np.repeat(self.itr,len(latent))\n",
    "\n",
    "            df_new[\"label\"]=self.plt_y\n",
    "            self.df=self.df.append(df_new)\n",
    "        self.itr+=1\n",
    "    def normalize(self):\n",
    "        # Normalize latent by maximum value\n",
    "        self.mx_norm=np.linalg.norm(self.df[[\"f1\",\"f2\"]].values,axis=1).max()\n",
    "        self.df[[\"f1\",'f2']]=self.df[[\"f1\",'f2']].apply(lambda x: x/self.mx_norm)\n",
    "\n",
    "        # Project latents into arc\n",
    "        df=self.df.copy()\n",
    "        norm=np.linalg.norm(df[[\"f1\",\"f2\"]].values,axis=1,keepdims=True)\n",
    "        df[[\"f1\",'f2']]=df[[\"f1\",'f2']].values/norm\n",
    "        df[\"arc\"]=df[\"arc\"].map({0.5:0.9},na_action=None)\n",
    "        \n",
    "        self.df=self.df.append(df)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "317a2e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "plt_x,plt_y=x_test[:batch_size],y_test[:batch_size]\n",
    "lg=LogLatent(enc,plt_x,plt_y.argmax(-1))\n",
    "\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train,y_train)).cache().shuffle(len(x_train)//2).batch(batch_size)\n",
    "val_loader = tf.data.Dataset.from_tensor_slices((x_val,y_val)).cache().shuffle(len(x_val)//2).batch(batch_size*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04d2ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in train_loader:\n",
    "    pass\n",
    "for ii in val_loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80836002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 6s 10ms/step - loss: 1.6129 - accuracy: 0.3873 - val_loss: 0.8175 - val_accuracy: 0.6994\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.7356 - accuracy: 0.7599 - val_loss: 0.5843 - val_accuracy: 0.8304\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.5581 - accuracy: 0.8374 - val_loss: 0.5103 - val_accuracy: 0.8560\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.4837 - accuracy: 0.8632 - val_loss: 0.4487 - val_accuracy: 0.8737\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.4258 - accuracy: 0.8819 - val_loss: 0.4259 - val_accuracy: 0.8846\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.3838 - accuracy: 0.8932 - val_loss: 0.3981 - val_accuracy: 0.8907\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.3631 - accuracy: 0.8994 - val_loss: 0.3917 - val_accuracy: 0.8907\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.3421 - accuracy: 0.9052 - val_loss: 0.3608 - val_accuracy: 0.9017\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.3150 - accuracy: 0.9120 - val_loss: 0.3574 - val_accuracy: 0.9003\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.3063 - accuracy: 0.9124 - val_loss: 0.3516 - val_accuracy: 0.9005\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.fit(train_loader, \n",
    "              epochs=epochs,\n",
    "              validation_data=val_loader,\n",
    "              callbacks=[lg])\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0d23d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.9076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3286300003528595, 0.9075999855995178]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "234fdaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=px.scatter(lg.df, x=\"f1\", y=\"f2\", animation_frame=\"iterations\", color=\"label\",opacity=lg.df.arc,\n",
    "                range_x=[-1.5,1.5],\n",
    "              range_y=[-1.5,1.5])\n",
    "fig.update_yaxes(\n",
    "    scaleanchor = \"x\",\n",
    "    scaleratio = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eae75d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"history/dense_tf.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83913aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
