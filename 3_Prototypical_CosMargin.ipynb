{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eee37772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.16.6\n",
      "Uninstalling numpy-1.16.6:\n",
      "  Successfully uninstalled numpy-1.16.6\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.7 MB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorlayer 2.1.0 requires numpy<1.17,>=1.16, but you have numpy 1.21.4 which is incompatible.\n",
      "tensorflow 2.4.1 requires numpy~=1.19.2, but you have numpy 1.21.4 which is incompatible.\n",
      "tensorflow 2.4.1 requires wrapt~=1.12.1, but you have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.21.4\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f40f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.callbacks as cb\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215d8f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6094d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b27ad5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=10\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "y_train_1hot = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_1hot = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5f200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "meta_batch_size = 32\n",
    "epochs = 10\n",
    "plt_x,plt_y=x_test[:batch_size],y_test[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fa8dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "all_class_list=[train_loader.filter(lambda x,y: y==yy)\n",
    "                  .cache()\n",
    "                  .shuffle(2000)\n",
    "                  .prefetch(50)\n",
    "                 for yy in range(num_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dbcfd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAYS=5\n",
    "SHOTS=3\n",
    "W,H,CH=28,28,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0277395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_meta2(dataset_list,mult=4):\n",
    "    orders=np.concatenate([np.random.permutation(len(dataset_list)) for x in range(mult)])\n",
    "    for tasks in range(len(orders)//WAYS):\n",
    "        #從已決定好的順序拉出WAY個class#\n",
    "        picked=[dataset_list[tt] for tt in orders[WAYS*tasks:WAYS*(tasks+1)]]\n",
    "        #每個class抽SHOTS+1張#\n",
    "        data = [next(iter(class_loader.batch(SHOTS+1)))[0] for class_loader in picked]\n",
    "        #support每個class各有SHOTS張照片#\n",
    "        support=tf.concat([d[:-1] for d in data],axis=0)\n",
    "        #query挑每個class 1 張，順序不固定#\n",
    "        idxs=np.random.choice(range(WAYS), size=WAYS, replace=False)\n",
    "        query=tf.concat([data[wayid][-2:-1] for wayid in idxs],axis=0)\n",
    "        #輸出的時候把support跟query接在一起#\n",
    "        yield tf.concat([support, query], axis=0), tf.stack([keras.utils.to_categorical(idx,num_classes=WAYS) for idx in idxs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ed454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULT=400\n",
    "train_meta_loader=tf.data.Dataset.from_generator(partial(form_meta2,all_class_list,MULT),\n",
    "                                                 output_types=(tf.float32,tf.float32),\n",
    "                                                output_shapes=((WAYS*(SHOTS+1),W,H,CH),(WAYS,WAYS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34266498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.230 sec\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "for ld in all_class_list:\n",
    "    for xx,yy in ld.batch(500):\n",
    "        pass\n",
    "print(f\"{time.time()-start_time:.03f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9a26605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.557 sec\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "for ld in all_class_list:\n",
    "    for xx,yy in ld.batch(500):\n",
    "        pass\n",
    "print(f\"{time.time()-start_time:.03f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5fe55ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding ##\n",
    "class Encoder(keras.Model):\n",
    "    def __init__(self,n_layers=2,latent_features=2,hidden_featrues=64):\n",
    "        super().__init__()\n",
    "        self.latent_features=latent_features\n",
    "        # First Layer\n",
    "        self.conv_0=keras.layers.Conv2D(hidden_featrues, kernel_size=3, activation=\"relu\",padding='same')\n",
    "        self.dropout_0=keras.layers.Dropout(0.2)\n",
    "        # Middle Layers\n",
    "        self.convs=[keras.layers.Conv2D(hidden_featrues, kernel_size=3, activation=\"relu\",padding='same') for _ in range(n_layers)]\n",
    "        self.mxpools = [keras.layers.MaxPooling2D(pool_size=2) for _ in range(n_layers)]\n",
    "        self.dropouts = [keras.layers.Dropout(0.2) for _ in range(n_layers)]\n",
    "        # Integration Layer(Output Layer)\n",
    "        WIDTH=2\n",
    "        self.gap=keras.layers.AveragePooling2D(pool_size=WIDTH,)\n",
    "        self.flatten=keras.layers.Flatten()\n",
    "        self.dense=keras.layers.Dense(latent_features)\n",
    "      \n",
    "    def call(self,x):\n",
    "        x=self.dropout_0(self.conv_0(x))\n",
    "        for conv,mxp,drp in zip(self.convs,self.mxpools,self.dropouts):\n",
    "            x=drp(mxp(conv(x)))\n",
    "        x=self.gap(x)\n",
    "        x=self.flatten(x)\n",
    "        y=self.dense(x)\n",
    "        return y\n",
    "\n",
    "## Special Layers ##\n",
    "\n",
    "class MatMul:\n",
    "    def __init__(self,mode=\"paired\"):\n",
    "        self.mode=mode\n",
    "        assert mode in [\"paired\",\"cross\"]\n",
    "    def __call__(self,q,s):\n",
    "        if self.mode==\"paired\":\n",
    "            return tf.reduce_sum(tf.multiply(q,s),axis=-1,keepdims=True)\n",
    "        if self.mode==\"cross\":\n",
    "            return tf.matmul(q,s,transpose_b=True)\n",
    "        \n",
    "class EuclideanDist:\n",
    "    def __init__(self,mode=\"paired\"):\n",
    "        self.mode=mode\n",
    "        assert mode in [\"paired\",\"cross\"]\n",
    "        \n",
    "    def __call__(self,q,s):\n",
    "        if self.mode==\"paired\":\n",
    "            dist=tf.math.reduce_euclidean_norm(q-s,axis=-1,keepdims=True)\n",
    "        if self.mode==\"cross\":\n",
    "            dist=-tf.math.reduce_euclidean_norm(\n",
    "                tf.stack([q[:,qq:qq+1]-s for qq in range(q.shape[1])],axis=1)\n",
    "                ,axis=-1,keepdims=False)\n",
    "            \n",
    "        return dist\n",
    "\n",
    "class CosSim:\n",
    "    def __init__(self,mode=\"paired\"):\n",
    "        self.mode=mode\n",
    "        assert mode in [\"paired\",\"cross\"]\n",
    "        self.matmul=MatMul(mode)\n",
    "    def __call__(self,q,s):\n",
    "        query_n=tf.math.l2_normalize(q, axis=-1)\n",
    "        support_n=tf.math.l2_normalize(s, axis=-1)\n",
    "        return self.matmul(query_n,support_n)\n",
    "    \n",
    "class CosineLayer(keras.layers.Layer):\n",
    "    def __init__(self, out_features=10,mode=\"cross\"):\n",
    "        super().__init__()\n",
    "        self.out_features = out_features\n",
    "        self.cos_sim=CosSim(mode)\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(self.out_features,input_shape[-1]),\n",
    "                               initializer='glorot_uniform',\n",
    "                               trainable=True)\n",
    "    def call(self, inputs):\n",
    "        return self.cos_sim(inputs,self.w)\n",
    "\n",
    "## Loss function ##\n",
    "class ContrastiveLoss:\n",
    "    def __init__(self,m=1,mode=\"dist\"):\n",
    "        \n",
    "        self.mode=mode\n",
    "        if self.mode==\"dist\":\n",
    "            self.m=m\n",
    "        if self.mode==\"cos\" or self.mode==\"matmul\":\n",
    "            self.activation=keras.activations.sigmoid\n",
    "            self.loss_fn=keras.losses.BinaryCrossentropy()\n",
    "        assert mode in [\"dist\",\"cos\",\"matmul\"]\n",
    "        self.__name__=\"loss\"\n",
    "    def __call__(self,y_true, y_pred):\n",
    "        if self.mode==\"dist\":\n",
    "            loss=tf.reduce_mean(y_true * tf.square(y_pred) +\n",
    "                                 (1 - y_true)* tf.square(tf.maximum(self.m - y_pred, 0)),\n",
    "                               axis=-1,keepdims=True)\n",
    "        if self.mode==\"cos\" or self.mode==\"matmul\":\n",
    "            loss=self.loss_fn(y_true,self.activation(y_pred))\n",
    "        return loss\n",
    "    \n",
    "class FocalLoss:\n",
    "    def __init__(self, gamma=3, eps=1e-10):\n",
    "        self.gamma = gamma\n",
    "        self.eps = tf.constant(eps)\n",
    "        self.cce=keras.losses.CategoricalCrossentropy(from_logits=True,reduction=tf.keras.losses.Reduction.NONE)\n",
    "        self.__name__=\"loss\"\n",
    "    def __call__(self,y_true, y_pred):\n",
    "        logp = self.cce(y_true,y_pred)\n",
    "        p = tf.exp(-logp)\n",
    "        loss = (tf.constant(1.) - p) ** self.gamma * logp\n",
    "        return tf.reduce_mean(loss, axis=-1)\n",
    "    \n",
    "class AddMarginLoss():\n",
    "    def __init__(self,s=5,m=0.3,gamma=3):\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.lossfn=FocalLoss(gamma)\n",
    "        self.__name__=\"loss\"\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        cosine=y_pred\n",
    "        phi = cosine - self.m\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        arc = (y_true * phi) + ((1.0 - y_true) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n",
    "        arc *= self.s\n",
    "        return self.lossfn(y_true,arc)\n",
    "    \n",
    "class ArcMarginLoss():\n",
    "    def __init__(self,s=32,m=0.3,easy_margin=False,gamma=3, eps=1e-6):\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.eps=tf.constant(eps)# This is very, very, very important\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "        \n",
    "        self.lossfn=FocalLoss(gamma)\n",
    "        self.__name__=\"loss\"\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        cosine=y_pred\n",
    "        \n",
    "        sine = tf.sqrt(tf.constant(1.) - tf.pow(cosine, 2) + self.eps)\n",
    "        \n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where((cosine - self.th) > 0, phi, cosine - self.mm)\n",
    "        \n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        arc = (y_true * phi) + ((1.0 - y_true) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n",
    "        arc *= self.s\n",
    "        return self.lossfn(y_true,arc)\n",
    "    \n",
    "## Main Model ##\n",
    "class ClassModel(keras.Model):\n",
    "    def __init__(self,encoder,out_features=10,mode=\"dense\"):\n",
    "        super().__init__()\n",
    "        assert mode in [\"dense\",\"cosmargin\",\"arcmargin\"]\n",
    "        self.encoder=encoder\n",
    "        self.mode=mode\n",
    "        self.latent_features=encoder.latent_features\n",
    "        \n",
    "        if self.mode==\"dense\":\n",
    "            self.output_layer=keras.layers.Dense(out_features,use_bias=False)\n",
    "            self.loss_fn=FocalLoss(3)\n",
    "            return\n",
    "        \n",
    "        self.output_layer=CosineLayer(out_features)\n",
    "        if self.mode==\"cosmargin\":\n",
    "            self.loss_fn=AddMarginLoss(s=5,m=0.3)\n",
    "        if self.mode==\"arcmargin\":\n",
    "            self.loss_fn=ArcMarginLoss(s=5,m=0.4,easy_margin=False)\n",
    "        \n",
    "    def call(self,x,training=False):\n",
    "        latent=self.encoder(x)\n",
    "        return self.output_layer(latent)\n",
    "\n",
    "class SiameseModel(keras.Model):\n",
    "    # Mode: dist= euclidean distance\n",
    "    #       cos = cosine distance\n",
    "    #       matmult= matric multiplication distance\n",
    "    def __init__(self,encoder,mode=\"cos\"):\n",
    "        super().__init__()\n",
    "        assert mode in [\"dist\",\"cos\",\"matmul\"]\n",
    "        self.encoder=encoder\n",
    "        self.mode=mode\n",
    "        self.latent_features=encoder.latent_features\n",
    "        if self.mode==\"dist\":\n",
    "            self.matric_fn=EuclideanDist(\"paired\")\n",
    "        if self.mode==\"cos\":\n",
    "            self.matric_fn=CosSim(\"paired\")\n",
    "        if self.mode==\"matmul\":\n",
    "            self.matric_fn=MatMul(\"paired\")\n",
    "        self.loss_fn=ContrastiveLoss(1,mode=mode)\n",
    "            \n",
    "    def call(self,x,training=False):\n",
    "        latent_s=self.encoder(x[:,0])\n",
    "        latent_q=self.encoder(x[:,1])\n",
    "\n",
    "        return self.matric_fn(latent_q,latent_s)     \n",
    "  \n",
    "    \n",
    "class PrototypicalNetworks(keras.Model):\n",
    "    # Mode: dist= euclidean distance\n",
    "    #       cos = cosine distance\n",
    "    #       matmult= matric multiplication distance\n",
    "    def __init__(self,encoder,mode=\"cos\"):\n",
    "        super().__init__()\n",
    "        assert mode in [\"dist\",\"cos\",\"matmul\",\"cosmargin\",\"arcmargin\"]\n",
    "        self.encoder=encoder\n",
    "        self.mode=mode\n",
    "        self.latent_features=encoder.latent_features\n",
    "        #Metric function#    \n",
    "        if mode in [\"cos\",\"cosmargin\",\"arcmargin\"]:\n",
    "            self.matric_fn=CosSim(\"cross\")\n",
    "        if self.mode==\"dist\":\n",
    "            self.matric_fn=EuclideanDist(\"cross\")\n",
    "        if self.mode==\"matmul\":\n",
    "            self.matric_fn=MatMul(\"cross\")\n",
    "        #Loss function, including output activation#\n",
    "        if mode in [\"dist\",\"cos\",\"matmul\"]:\n",
    "            self.loss_fn=FocalLoss(3)\n",
    "        if self.mode==\"cosmargin\":\n",
    "            self.loss_fn=AddMarginLoss(s=5,m=0.3)\n",
    "        if self.mode==\"arcmargin\":\n",
    "            self.loss_fn=ArcMarginLoss(s=5,m=0.4,easy_margin=False)  \n",
    "            \n",
    "    def call(self,x,training=False):\n",
    "        # 計算query latent\n",
    "        latent_q=tf.stack([self.encoder(x[:,WAYS*SHOTS+ii]) for ii in range(WAYS)],axis=1)        \n",
    "        \n",
    "        # 計算 prototypes\n",
    "        latent_s=[self.encoder(x[:,ii]) for ii in range(WAYS*SHOTS)]\n",
    "        latent_proto=tf.stack([tf.reduce_mean(tf.stack(latent_s[ww*SHOTS:(ww+1)*SHOTS],axis=-1),axis=-1)\n",
    "                     for ww in range(WAYS)],axis=1)\n",
    "        # 計算metric\n",
    "        return self.matric_fn(latent_q,latent_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e982baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=Encoder(n_layers=2,latent_features=2,hidden_featrues=64)\n",
    "model=PrototypicalNetworks(enc,mode=\"cosmargin\")# {\"dist\",\"cos\",\"matmul\",\"cosmargin\",\"arcmargin\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c043f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn=ArcMarginLoss(s=5,m=0.4,easy_margin=False)\n",
    "loss_fn=model.loss_fn\n",
    "opt=keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=loss_fn, optimizer=opt, metrics=[keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad19b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recording Callbacks\n",
    "class LogLatent(keras.callbacks.Callback):\n",
    "    def __init__(self,encoder,test_x,test_y,skip_iters=100):\n",
    "        self.df=self.df=pd.DataFrame()\n",
    "        self.encoder=encoder\n",
    "        self.plt_x=test_x\n",
    "        self.plt_y=test_y\n",
    "        self.itr=0\n",
    "        self.skip_iters=skip_iters\n",
    "    def on_batch_end(self,batch, logs={}):\n",
    "        if self.itr%self.skip_iters==self.skip_iters-1:\n",
    "            latent=self.encoder(self.plt_x)\n",
    "            df_new=pd.DataFrame()\n",
    "            df_new[\"f1\"]=latent[:,0]\n",
    "            df_new[\"f2\"]=latent[:,1]\n",
    "            df_new[\"arc\"]=0.5\n",
    "            df_new[\"iterations\"]=np.repeat(self.itr,len(latent))\n",
    "\n",
    "            df_new[\"label\"]=self.plt_y\n",
    "            self.df=self.df.append(df_new)\n",
    "        self.itr+=1\n",
    "    def normalize(self):\n",
    "        # Normalize latent by maximum value\n",
    "        self.mx_norm=np.linalg.norm(self.df[[\"f1\",\"f2\"]].values[-len(self.plt_y):],axis=1).max()\n",
    "        self.df[[\"f1\",'f2']]=self.df[[\"f1\",'f2']].apply(lambda x: x/self.mx_norm)\n",
    "\n",
    "        # Project latents into arc\n",
    "        df=self.df.copy()\n",
    "        norm=np.linalg.norm(df[[\"f1\",\"f2\"]].values,axis=1,keepdims=True)\n",
    "        df[[\"f1\",'f2']]=df[[\"f1\",'f2']].values/norm\n",
    "        df[\"arc\"]=df[\"arc\"].map({0.5:0.9},na_action=None)\n",
    "        \n",
    "        self.df=self.df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59cc9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = train_meta_loader.shuffle(1000).cache().prefetch(meta_batch_size).batch(meta_batch_size)\n",
    "\n",
    "val_loader = train_meta_loader.shuffle(1000).cache().prefetch(meta_batch_size*4).batch(meta_batch_size*4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4c94bdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "25/25 [==============================] - 1820s 38s/step - loss: 2.5752 - categorical_accuracy: 0.3791 - val_loss: 1.7508 - val_categorical_accuracy: 0.4882\n",
      "Epoch 2/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 1.8175 - categorical_accuracy: 0.4805 - val_loss: 1.4868 - val_categorical_accuracy: 0.5970\n",
      "Epoch 3/800\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 1.6351 - categorical_accuracy: 0.5460 - val_loss: 1.2780 - val_categorical_accuracy: 0.6440\n",
      "Epoch 4/800\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 1.3813 - categorical_accuracy: 0.6103 - val_loss: 1.1380 - val_categorical_accuracy: 0.6880\n",
      "Epoch 5/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 1.2048 - categorical_accuracy: 0.6639 - val_loss: 0.8962 - val_categorical_accuracy: 0.7387\n",
      "Epoch 6/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.9704 - categorical_accuracy: 0.7021 - val_loss: 0.8556 - val_categorical_accuracy: 0.7600\n",
      "Epoch 7/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.8968 - categorical_accuracy: 0.7333 - val_loss: 0.8219 - val_categorical_accuracy: 0.7770\n",
      "Epoch 8/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.8387 - categorical_accuracy: 0.7500 - val_loss: 0.8470 - val_categorical_accuracy: 0.7753\n",
      "Epoch 9/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.7949 - categorical_accuracy: 0.7479 - val_loss: 0.7301 - val_categorical_accuracy: 0.8027\n",
      "Epoch 10/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.7607 - categorical_accuracy: 0.7674 - val_loss: 0.6620 - val_categorical_accuracy: 0.8125\n",
      "Epoch 11/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.7124 - categorical_accuracy: 0.7815 - val_loss: 0.8948 - val_categorical_accuracy: 0.7875\n",
      "Epoch 12/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.8909 - categorical_accuracy: 0.7526 - val_loss: 0.6819 - val_categorical_accuracy: 0.8183\n",
      "Epoch 13/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.6898 - categorical_accuracy: 0.7879 - val_loss: 0.6167 - val_categorical_accuracy: 0.8390\n",
      "Epoch 14/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.6303 - categorical_accuracy: 0.8137 - val_loss: 0.5980 - val_categorical_accuracy: 0.8487\n",
      "Epoch 15/800\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.6068 - categorical_accuracy: 0.8264 - val_loss: 0.6079 - val_categorical_accuracy: 0.8505\n",
      "Epoch 16/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.5998 - categorical_accuracy: 0.8339 - val_loss: 0.5851 - val_categorical_accuracy: 0.8605\n",
      "Epoch 17/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.5885 - categorical_accuracy: 0.8374 - val_loss: 0.5710 - val_categorical_accuracy: 0.8627\n",
      "Epoch 18/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.5842 - categorical_accuracy: 0.8329 - val_loss: 0.5725 - val_categorical_accuracy: 0.8627\n",
      "Epoch 19/800\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.5584 - categorical_accuracy: 0.8494 - val_loss: 0.5830 - val_categorical_accuracy: 0.8665\n",
      "Epoch 20/800\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.5756 - categorical_accuracy: 0.8501 - val_loss: 0.5589 - val_categorical_accuracy: 0.8658\n",
      "Epoch 21/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.5351 - categorical_accuracy: 0.8652 - val_loss: 0.5419 - val_categorical_accuracy: 0.8765\n",
      "Epoch 22/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.5241 - categorical_accuracy: 0.8617 - val_loss: 0.5292 - val_categorical_accuracy: 0.8823\n",
      "Epoch 23/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.5337 - categorical_accuracy: 0.8721 - val_loss: 0.5268 - val_categorical_accuracy: 0.8857\n",
      "Epoch 24/800\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.5216 - categorical_accuracy: 0.8676 - val_loss: 0.5249 - val_categorical_accuracy: 0.8845\n",
      "Epoch 25/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.5095 - categorical_accuracy: 0.8746 - val_loss: 0.5190 - val_categorical_accuracy: 0.8885\n",
      "Epoch 26/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.5067 - categorical_accuracy: 0.8767 - val_loss: 0.5086 - val_categorical_accuracy: 0.8878\n",
      "Epoch 27/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.4994 - categorical_accuracy: 0.8719 - val_loss: 0.5046 - val_categorical_accuracy: 0.8942\n",
      "Epoch 28/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.4931 - categorical_accuracy: 0.8807 - val_loss: 0.5492 - val_categorical_accuracy: 0.8842\n",
      "Epoch 29/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.5026 - categorical_accuracy: 0.8778 - val_loss: 0.5170 - val_categorical_accuracy: 0.8955\n",
      "Epoch 30/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.4951 - categorical_accuracy: 0.8819 - val_loss: 0.4955 - val_categorical_accuracy: 0.8953\n",
      "Epoch 31/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.4771 - categorical_accuracy: 0.8896 - val_loss: 0.4992 - val_categorical_accuracy: 0.9013\n",
      "Epoch 32/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.4708 - categorical_accuracy: 0.8881 - val_loss: 0.4893 - val_categorical_accuracy: 0.9025\n",
      "Epoch 33/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.4584 - categorical_accuracy: 0.8900 - val_loss: 0.4906 - val_categorical_accuracy: 0.9080\n",
      "Epoch 34/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.4554 - categorical_accuracy: 0.8941 - val_loss: 0.4787 - val_categorical_accuracy: 0.9100\n",
      "Epoch 35/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.4328 - categorical_accuracy: 0.9103 - val_loss: 0.4734 - val_categorical_accuracy: 0.9140\n",
      "Epoch 36/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.4419 - categorical_accuracy: 0.9065 - val_loss: 0.4719 - val_categorical_accuracy: 0.9147\n",
      "Epoch 37/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.4488 - categorical_accuracy: 0.8990 - val_loss: 0.4708 - val_categorical_accuracy: 0.9180\n",
      "Epoch 38/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.4284 - categorical_accuracy: 0.9077 - val_loss: 0.4861 - val_categorical_accuracy: 0.9170\n",
      "Epoch 39/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.4444 - categorical_accuracy: 0.9056 - val_loss: 0.4718 - val_categorical_accuracy: 0.9180\n",
      "Epoch 40/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.4432 - categorical_accuracy: 0.9095 - val_loss: 0.4614 - val_categorical_accuracy: 0.9187\n",
      "Epoch 41/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.4239 - categorical_accuracy: 0.9175 - val_loss: 0.4608 - val_categorical_accuracy: 0.9262\n",
      "Epoch 42/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.4252 - categorical_accuracy: 0.9167 - val_loss: 0.4701 - val_categorical_accuracy: 0.9202\n",
      "Epoch 43/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.4204 - categorical_accuracy: 0.9241 - val_loss: 0.4591 - val_categorical_accuracy: 0.9277\n",
      "Epoch 44/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.4238 - categorical_accuracy: 0.9242 - val_loss: 0.4549 - val_categorical_accuracy: 0.9310\n",
      "Epoch 45/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3977 - categorical_accuracy: 0.9288 - val_loss: 0.4535 - val_categorical_accuracy: 0.9323\n",
      "Epoch 46/800\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.4032 - categorical_accuracy: 0.9288 - val_loss: 0.4543 - val_categorical_accuracy: 0.9275\n",
      "Epoch 47/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.4197 - categorical_accuracy: 0.9267 - val_loss: 0.4636 - val_categorical_accuracy: 0.9273\n",
      "Epoch 48/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.4071 - categorical_accuracy: 0.9302 - val_loss: 0.4473 - val_categorical_accuracy: 0.9340\n",
      "Epoch 49/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3935 - categorical_accuracy: 0.9373 - val_loss: 0.4460 - val_categorical_accuracy: 0.9330\n",
      "Epoch 50/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3903 - categorical_accuracy: 0.9340 - val_loss: 0.4418 - val_categorical_accuracy: 0.9327\n",
      "Epoch 51/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3807 - categorical_accuracy: 0.9397 - val_loss: 0.4379 - val_categorical_accuracy: 0.9352\n",
      "Epoch 52/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3897 - categorical_accuracy: 0.9377 - val_loss: 0.4439 - val_categorical_accuracy: 0.9373\n",
      "Epoch 53/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3895 - categorical_accuracy: 0.9367 - val_loss: 0.4392 - val_categorical_accuracy: 0.9350\n",
      "Epoch 54/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3821 - categorical_accuracy: 0.9377 - val_loss: 0.4354 - val_categorical_accuracy: 0.9373\n",
      "Epoch 55/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3806 - categorical_accuracy: 0.9407 - val_loss: 0.4349 - val_categorical_accuracy: 0.9395\n",
      "Epoch 56/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.3805 - categorical_accuracy: 0.9443 - val_loss: 0.4397 - val_categorical_accuracy: 0.9405\n",
      "Epoch 57/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3773 - categorical_accuracy: 0.9423 - val_loss: 0.4304 - val_categorical_accuracy: 0.9410\n",
      "Epoch 58/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.3690 - categorical_accuracy: 0.9487 - val_loss: 0.4356 - val_categorical_accuracy: 0.9408\n",
      "Epoch 59/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3738 - categorical_accuracy: 0.9440 - val_loss: 0.4333 - val_categorical_accuracy: 0.9427\n",
      "Epoch 60/800\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.3665 - categorical_accuracy: 0.9481 - val_loss: 0.4295 - val_categorical_accuracy: 0.9417\n",
      "Epoch 61/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3600 - categorical_accuracy: 0.9553 - val_loss: 0.4382 - val_categorical_accuracy: 0.9395\n",
      "Epoch 62/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3641 - categorical_accuracy: 0.9455 - val_loss: 0.4280 - val_categorical_accuracy: 0.9440\n",
      "Epoch 63/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3736 - categorical_accuracy: 0.9437 - val_loss: 0.4348 - val_categorical_accuracy: 0.9445\n",
      "Epoch 64/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.3626 - categorical_accuracy: 0.9450 - val_loss: 0.4395 - val_categorical_accuracy: 0.9385\n",
      "Epoch 65/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3752 - categorical_accuracy: 0.9455 - val_loss: 0.4308 - val_categorical_accuracy: 0.9402\n",
      "Epoch 66/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3570 - categorical_accuracy: 0.9537 - val_loss: 0.4415 - val_categorical_accuracy: 0.9398\n",
      "Epoch 67/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3661 - categorical_accuracy: 0.9503 - val_loss: 0.4337 - val_categorical_accuracy: 0.9415\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 68/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3544 - categorical_accuracy: 0.9511 - val_loss: 0.4331 - val_categorical_accuracy: 0.9435\n",
      "Epoch 69/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3383 - categorical_accuracy: 0.9603 - val_loss: 0.4350 - val_categorical_accuracy: 0.9427\n",
      "Epoch 70/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3474 - categorical_accuracy: 0.9541 - val_loss: 0.4318 - val_categorical_accuracy: 0.9442\n",
      "Epoch 71/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3383 - categorical_accuracy: 0.9533 - val_loss: 0.4284 - val_categorical_accuracy: 0.9470\n",
      "Epoch 72/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3402 - categorical_accuracy: 0.9522 - val_loss: 0.4263 - val_categorical_accuracy: 0.9470\n",
      "Epoch 73/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3438 - categorical_accuracy: 0.9598 - val_loss: 0.4260 - val_categorical_accuracy: 0.9480\n",
      "Epoch 74/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3327 - categorical_accuracy: 0.9628 - val_loss: 0.4260 - val_categorical_accuracy: 0.9473\n",
      "Epoch 75/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.3396 - categorical_accuracy: 0.9553 - val_loss: 0.4286 - val_categorical_accuracy: 0.9475\n",
      "Epoch 76/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.3317 - categorical_accuracy: 0.9613 - val_loss: 0.4249 - val_categorical_accuracy: 0.9490\n",
      "Epoch 77/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3394 - categorical_accuracy: 0.9557 - val_loss: 0.4267 - val_categorical_accuracy: 0.9477\n",
      "Epoch 78/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3320 - categorical_accuracy: 0.9575 - val_loss: 0.4255 - val_categorical_accuracy: 0.9480\n",
      "Epoch 79/800\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.3334 - categorical_accuracy: 0.9599 - val_loss: 0.4253 - val_categorical_accuracy: 0.9498\n",
      "Epoch 80/800\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.3399 - categorical_accuracy: 0.9547 - val_loss: 0.4270 - val_categorical_accuracy: 0.9488\n",
      "Epoch 81/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3385 - categorical_accuracy: 0.9610 - val_loss: 0.4262 - val_categorical_accuracy: 0.9490\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 82/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3360 - categorical_accuracy: 0.9606 - val_loss: 0.4260 - val_categorical_accuracy: 0.9492\n",
      "Epoch 83/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.3354 - categorical_accuracy: 0.9629 - val_loss: 0.4256 - val_categorical_accuracy: 0.9495\n",
      "Epoch 84/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.3250 - categorical_accuracy: 0.9635 - val_loss: 0.4254 - val_categorical_accuracy: 0.9495\n",
      "Epoch 85/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3335 - categorical_accuracy: 0.9595 - val_loss: 0.4254 - val_categorical_accuracy: 0.9492\n",
      "Epoch 86/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3305 - categorical_accuracy: 0.9621 - val_loss: 0.4254 - val_categorical_accuracy: 0.9492\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 87/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3356 - categorical_accuracy: 0.9585 - val_loss: 0.4254 - val_categorical_accuracy: 0.9492\n",
      "Epoch 88/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3257 - categorical_accuracy: 0.9606 - val_loss: 0.4253 - val_categorical_accuracy: 0.9492\n",
      "Epoch 89/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.3313 - categorical_accuracy: 0.9578 - val_loss: 0.4253 - val_categorical_accuracy: 0.9495\n",
      "Epoch 90/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3290 - categorical_accuracy: 0.9613 - val_loss: 0.4253 - val_categorical_accuracy: 0.9495\n",
      "Epoch 91/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.3240 - categorical_accuracy: 0.9661 - val_loss: 0.4253 - val_categorical_accuracy: 0.9495\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 92/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.3346 - categorical_accuracy: 0.9604 - val_loss: 0.4253 - val_categorical_accuracy: 0.9495\n",
      "Epoch 93/800\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.3310 - categorical_accuracy: 0.9642 - val_loss: 0.4253 - val_categorical_accuracy: 0.9495\n",
      "Epoch 94/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3326 - categorical_accuracy: 0.9590 - val_loss: 0.4253 - val_categorical_accuracy: 0.9495\n",
      "Epoch 95/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3319 - categorical_accuracy: 0.9586 - val_loss: 0.4253 - val_categorical_accuracy: 0.9495\n",
      "Epoch 96/800\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.3372 - categorical_accuracy: 0.9557 - val_loss: 0.4253 - val_categorical_accuracy: 0.9495\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00096: early stopping\n"
     ]
    }
   ],
   "source": [
    "lg=LogLatent(enc,plt_x,plt_y)\n",
    "reduce_lr = cb.ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=5, min_lr=1e-8, verbose=1)\n",
    "earlystop=cb.EarlyStopping(monitor='val_loss',patience=20,restore_best_weights=True, verbose=1)\n",
    "try:\n",
    "    model.fit(train_loader, \n",
    "              epochs=800,\n",
    "              validation_data=val_loader,\n",
    "              callbacks=[lg,reduce_lr,earlystop])\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8525b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08d7203",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig=px.scatter(lg.df, x=\"f1\", y=\"f2\", animation_frame=\"iterations\", color=\"label\",opacity=lg.df.arc,\n",
    "                range_x=[-1.5,1.5],\n",
    "              range_y=[-1.5,1.5])\n",
    "fig.update_yaxes(\n",
    "    scaleanchor = \"x\",\n",
    "    scaleratio = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88a2c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"history/proto_cosmargin_tf.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72f3fae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.,  6.,  6.,  9.,  7., 13.,  5.,  7.,  1.,  5.]),\n",
       " array([0.00168726, 0.0032819 , 0.00487654, 0.00647119, 0.00806583,\n",
       "        0.00966047, 0.01125512, 0.01284976, 0.0144444 , 0.01603905,\n",
       "        0.01763369], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(abs(tf.reduce_mean(enc.layers[3].weights[0],axis=[0,1,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3451e70d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
