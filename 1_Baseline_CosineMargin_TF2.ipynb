{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22227992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Using cached plotly-5.3.1-py2.py3-none-any.whl (23.9 MB)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly) (7.0.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from plotly) (1.15.0)\n",
      "Installing collected packages: plotly\n",
      "Successfully installed plotly-5.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de8149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc4355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d237affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c3c29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=10\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1395ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding ##\n",
    "class Encoder(keras.Model):\n",
    "    def __init__(self,n_layers=2,latent_features=2,hidden_featrues=64):\n",
    "        super().__init__()\n",
    "        self.latent_features=latent_features\n",
    "        # First Layer\n",
    "        self.conv_0=keras.layers.Conv2D(hidden_featrues, kernel_size=3, activation=\"relu\",padding='same')\n",
    "        self.dropout_0=keras.layers.Dropout(0.2)\n",
    "        # Middle Layers\n",
    "        self.convs=[keras.layers.Conv2D(hidden_featrues, kernel_size=3, activation=\"relu\",padding='same') for _ in range(n_layers)]\n",
    "        self.mxpools = [keras.layers.MaxPooling2D(pool_size=2) for _ in range(n_layers)]\n",
    "        self.dropouts = [keras.layers.Dropout(0.2) for _ in range(n_layers)]\n",
    "        # Integration Layer(Output Layer)\n",
    "        WIDTH=2\n",
    "        self.gap=keras.layers.AveragePooling2D(pool_size=WIDTH,)\n",
    "        self.flatten=keras.layers.Flatten()\n",
    "        self.dense=keras.layers.Dense(latent_features)\n",
    "      \n",
    "    def call(self,x):\n",
    "        x=self.dropout_0(self.conv_0(x))\n",
    "        for conv,mxp,drp in zip(self.convs,self.mxpools,self.dropouts):\n",
    "            x=drp(mxp(conv(x)))\n",
    "        x=self.gap(x)\n",
    "        x=self.flatten(x)\n",
    "        y=self.dense(x)\n",
    "        return y\n",
    "\n",
    "## Special Layers ##\n",
    "def cos_sim(q,s):\n",
    "    query=tf.math.l2_normalize(q, axis=-1)\n",
    "    support=tf.math.l2_normalize(s, axis=-1)\n",
    "    cosine=tf.matmul(query,support,transpose_b=True)\n",
    "    return cosine\n",
    "class CosineLayer(keras.layers.Layer):\n",
    "    def __init__(self, out_features=10):\n",
    "        super().__init__()\n",
    "        self.out_features = out_features\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(self.out_features,input_shape[-1]),\n",
    "                               initializer='glorot_uniform',\n",
    "                               trainable=True)\n",
    "    def call(self, inputs):\n",
    "        return cos_sim(inputs,self.w)\n",
    "\n",
    "## Main Model ##\n",
    "class ClassModel(keras.Model):\n",
    "    def __init__(self,encoder,out_features=10,mode=\"dense\"):\n",
    "        super().__init__()\n",
    "        self.encoder=encoder\n",
    "        self.mode=mode\n",
    "        latent_features=encoder.latent_features\n",
    "        \n",
    "        \n",
    "        if self.mode==\"dense\":\n",
    "            self.output_layer=keras.layers.Dense(out_features,use_bias=False)\n",
    "            self.out_func=keras.layers.Softmax()\n",
    "        if self.mode==\"cos\":\n",
    "            self.output_layer=CosineLayer(out_features)\n",
    "        \n",
    "    def call(self,x,training=False):\n",
    "        latent=self.encoder(x)\n",
    "        if self.mode==\"dense\":\n",
    "            y=self.out_func(self.output_layer(latent))\n",
    "            return y\n",
    "        if self.mode==\"cos\":\n",
    "            cosine=self.output_layer(latent)\n",
    "            return cosine\n",
    "\n",
    "## Loss function ##\n",
    "class FocalLoss():\n",
    "    def __init__(self, gamma=3, eps=1e-10):\n",
    "        self.gamma = gamma\n",
    "        self.eps = tf.constant(eps)\n",
    "        self.softmax =keras.layers.Softmax()\n",
    "        self.cce=keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "        \n",
    "    def __call__(self,y_true, y_pred): \n",
    "        logp = self.cce(y_true,self.softmax(y_pred+self.eps))\n",
    "        p = tf.exp(-logp)\n",
    "        loss = (tf.constant(1.) - p) ** self.gamma * logp\n",
    "        return tf.reduce_mean(loss, axis=-1)\n",
    "    \n",
    "class AddMarginLoss():\n",
    "    def __init__(self,s=5,m=0.3):\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.lossfn=FocalLoss()\n",
    "        self.__name__=\"loss\"\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        cosine=y_pred\n",
    "        phi = cosine - self.m\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        arc = (y_true * phi) + ((1.0 - y_true) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n",
    "        arc *= self.s\n",
    "        return self.lossfn(y_true,arc)\n",
    "    \n",
    "class ArcMarginLoss():\n",
    "    def __init__(self,s=32,m=0.3):\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "        \n",
    "        self.lossfn=FocalLoss()\n",
    "        self.__name__=\"loss\"\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        cosine=y_pred\n",
    "        \n",
    "        sine = tf.sqrt(tf.constant(1.) - tf.pow(cosine, 2))\n",
    "        \n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where((cosine - self.th) > 0, phi, cosine - self.mm)\n",
    "        \n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        arc = (y_true * phi) + ((1.0 - y_true) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n",
    "        arc *= self.s\n",
    "        return self.lossfn(y_true,arc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c6c5a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=Encoder(n_layers=2,latent_features=2,hidden_featrues=64)\n",
    "model=ClassModel(enc,out_features=10,mode=\"cos\")\n",
    "\n",
    "loss_fn=AddMarginLoss(s=5,m=0.3)\n",
    "model.compile(loss=loss_fn, optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7317fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in train_loader:\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b7edf762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.GradientTape() as tape:\n",
    "#     l,w=model(x)\n",
    "#     loss=loss_fn(y,(l,w))\n",
    "# gradient =tape.gradient(loss,model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "31d81111",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recording Callbacks\n",
    "\n",
    "class LogLatent(keras.callbacks.Callback):\n",
    "    def __init__(self,encoder,test_x,test_y,skip_iters=100):\n",
    "        self.df=self.df=pd.DataFrame()\n",
    "        self.encoder=encoder\n",
    "        self.plt_x=test_x\n",
    "        self.plt_y=test_y\n",
    "        self.itr=0\n",
    "        self.skip_iters=skip_iters\n",
    "    def on_batch_end(self,batch, logs={}):\n",
    "        if self.itr%self.skip_iters==self.skip_iters-1:\n",
    "            latent=self.encoder(self.plt_x)\n",
    "            df_new=pd.DataFrame()\n",
    "            df_new[\"f1\"]=latent[:,0]\n",
    "            df_new[\"f2\"]=latent[:,1]\n",
    "            df_new[\"arc\"]=0.5\n",
    "            df_new[\"iterations\"]=np.repeat(self.itr,len(latent))\n",
    "\n",
    "            df_new[\"label\"]=self.plt_y\n",
    "            self.df=self.df.append(df_new)\n",
    "        self.itr+=1\n",
    "    def normalize(self):\n",
    "        # Normalize latent by maximum value\n",
    "        self.mx_norm=np.linalg.norm(self.df[[\"f1\",\"f2\"]].values,axis=1).max()\n",
    "        self.df[[\"f1\",'f2']]=self.df[[\"f1\",'f2']].apply(lambda x: x/self.mx_norm)\n",
    "\n",
    "        # Project latents into arc\n",
    "        df=self.df.copy()\n",
    "        norm=np.linalg.norm(df[[\"f1\",\"f2\"]].values,axis=1,keepdims=True)\n",
    "        df[[\"f1\",'f2']]=df[[\"f1\",'f2']].values/norm\n",
    "        df[\"arc\"]=df[\"arc\"].map({0.5:0.9},na_action=None)\n",
    "        \n",
    "        self.df=self.df.append(df)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0deccf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "plt_x,plt_y=x_test[:batch_size],y_test[:batch_size]\n",
    "lg=LogLatent(enc,plt_x,plt_y.argmax(-1))\n",
    "\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train,y_train)).cache().shuffle(len(x_train)//2).batch(batch_size)\n",
    "val_loader = tf.data.Dataset.from_tensor_slices((x_val,y_val)).cache().shuffle(len(x_val)//2).batch(batch_size*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f706242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 5s 10ms/step - loss: 2.6289 - accuracy: 0.4029 - val_loss: 1.2892 - val_accuracy: 0.7368\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.2925 - accuracy: 0.7312 - val_loss: 1.1111 - val_accuracy: 0.8307\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.1723 - accuracy: 0.7929 - val_loss: 1.0332 - val_accuracy: 0.8714\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.1016 - accuracy: 0.8339 - val_loss: 1.0074 - val_accuracy: 0.8878\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0625 - accuracy: 0.8568 - val_loss: 1.0156 - val_accuracy: 0.8802\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0343 - accuracy: 0.8684 - val_loss: 0.9655 - val_accuracy: 0.9153\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0322 - accuracy: 0.8793 - val_loss: 0.9687 - val_accuracy: 0.9112\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0083 - accuracy: 0.8876 - val_loss: 0.9730 - val_accuracy: 0.9129\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0224 - accuracy: 0.8794 - val_loss: 0.9399 - val_accuracy: 0.9232\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9758 - accuracy: 0.9020 - val_loss: 1.1003 - val_accuracy: 0.8419\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.fit(train_loader, \n",
    "              epochs=epochs,\n",
    "              validation_data=val_loader,\n",
    "              callbacks=[lg])\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e954a276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 3ms/step - loss: 1.0720 - accuracy: 0.8503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0719693899154663, 0.8503000140190125]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3fd877a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866fa526",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=px.scatter(lg.df, x=\"f1\", y=\"f2\", animation_frame=\"iterations\", color=\"label\",opacity=lg.df.arc,\n",
    "                range_x=[-1.5,1.5],\n",
    "              range_y=[-1.5,1.5])\n",
    "fig.update_yaxes(\n",
    "    scaleanchor = \"x\",\n",
    "    scaleratio = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "400cdc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"history/cos_tf.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31887dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
