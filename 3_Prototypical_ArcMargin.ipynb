{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf2772",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "031f870b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.16.6\n",
      "Uninstalling numpy-1.16.6:\n",
      "  Successfully uninstalled numpy-1.16.6\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.7 MB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorlayer 2.1.0 requires numpy<1.17,>=1.16, but you have numpy 1.21.4 which is incompatible.\n",
      "tensorflow 2.4.1 requires numpy~=1.19.2, but you have numpy 1.21.4 which is incompatible.\n",
      "tensorflow 2.4.1 requires wrapt~=1.12.1, but you have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.21.4\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a620f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.callbacks as cb\n",
    "\n",
    "from utils import data_tools,config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f4694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)\n",
    "cfg=config.read_config(\"default.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a39bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "602458f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_1hot = keras.utils.to_categorical(y_train, cfg.n_classes)\n",
    "y_test_1hot = keras.utils.to_categorical(y_test, cfg.n_classes)\n",
    "\n",
    "plt_x,plt_y=x_test[:cfg.batch_size],y_test[:cfg.batch_size]\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b34329",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train_loader,meta_val_loader,source_class_loader,val_class_loader=data_tools.form_meta_loader(train_loader,cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0803dd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.595 sec\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "for ld in source_class_loader:\n",
    "    for xx,yy in ld.batch(500):\n",
    "        pass\n",
    "print(f\"{time.time()-start_time:.03f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "413fd02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.731 sec\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "for ld in val_class_loader:\n",
    "    for xx,yy in ld.batch(500):\n",
    "        pass\n",
    "print(f\"{time.time()-start_time:.03f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7278607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding ##\n",
    "class Encoder(keras.Model):\n",
    "    def __init__(self,n_layers=2,latent_features=2,hidden_featrues=64):\n",
    "        super().__init__()\n",
    "        self.latent_features=latent_features\n",
    "        # First Layer\n",
    "        self.conv_0=keras.layers.Conv2D(hidden_featrues, kernel_size=3, activation=\"relu\",padding='same')\n",
    "        self.dropout_0=keras.layers.Dropout(0.2)\n",
    "        # Middle Layers\n",
    "        self.convs=[keras.layers.Conv2D(hidden_featrues, kernel_size=3, activation=\"relu\",padding='same') for _ in range(n_layers)]\n",
    "        self.mxpools = [keras.layers.MaxPooling2D(pool_size=2) for _ in range(n_layers)]\n",
    "        self.dropouts = [keras.layers.Dropout(0.2) for _ in range(n_layers)]\n",
    "        # Integration Layer(Output Layer)\n",
    "        WIDTH=2\n",
    "        self.gap=keras.layers.AveragePooling2D(pool_size=WIDTH,)\n",
    "        self.flatten=keras.layers.Flatten()\n",
    "        self.dense=keras.layers.Dense(latent_features)\n",
    "      \n",
    "    def call(self,x):\n",
    "        x=self.dropout_0(self.conv_0(x))\n",
    "        for conv,mxp,drp in zip(self.convs,self.mxpools,self.dropouts):\n",
    "            x=drp(mxp(conv(x)))\n",
    "        x=self.gap(x)\n",
    "        x=self.flatten(x)\n",
    "        y=self.dense(x)\n",
    "        return y\n",
    "\n",
    "## Special Layers ##\n",
    "class MatMul:\n",
    "    def __init__(self,mode=\"paired\"):\n",
    "        self.mode=mode\n",
    "        assert mode in [\"paired\",\"cross\"]\n",
    "    def __call__(self,q,s):\n",
    "        if self.mode==\"paired\":\n",
    "            return tf.reduce_sum(tf.multiply(q,s),axis=-1,keepdims=True)\n",
    "        if self.mode==\"cross\":\n",
    "            return tf.matmul(q,s,transpose_b=True)\n",
    "        \n",
    "class EuclideanDist:\n",
    "    def __init__(self,mode=\"paired\"):\n",
    "        self.mode=mode\n",
    "        assert mode in [\"paired\",\"cross\"]\n",
    "        \n",
    "    def __call__(self,q,s):\n",
    "        if self.mode==\"paired\":\n",
    "            dist=tf.math.reduce_euclidean_norm(q-s,axis=-1,keepdims=True)\n",
    "        if self.mode==\"cross\":\n",
    "            dist=-tf.math.reduce_euclidean_norm(\n",
    "                tf.stack([q[:,qq:qq+1]-s for qq in range(q.shape[1])],axis=1)\n",
    "                ,axis=-1,keepdims=False)\n",
    "            \n",
    "        return dist\n",
    "\n",
    "class CosSim:\n",
    "    def __init__(self,mode=\"paired\"):\n",
    "        self.mode=mode\n",
    "        assert mode in [\"paired\",\"cross\"]\n",
    "        self.matmul=MatMul(mode)\n",
    "    def __call__(self,q,s):\n",
    "        query_n=tf.math.l2_normalize(q, axis=-1)\n",
    "        support_n=tf.math.l2_normalize(s, axis=-1)\n",
    "        return self.matmul(query_n,support_n)\n",
    "    \n",
    "class CosineLayer(keras.layers.Layer):\n",
    "    def __init__(self, out_features=10,mode=\"cross\"):\n",
    "        super().__init__()\n",
    "        self.out_features = out_features\n",
    "        self.cos_sim=CosSim(mode)\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(self.out_features,input_shape[-1]),\n",
    "                               initializer='glorot_uniform',\n",
    "                               trainable=True)\n",
    "    def call(self, inputs):\n",
    "        return self.cos_sim(inputs,self.w)\n",
    "\n",
    "\n",
    "    \n",
    "## Main Model ##\n",
    "class ClassModel(keras.Model):\n",
    "    def __init__(self,encoder,out_features=10,mode=\"dense\"):\n",
    "        super().__init__()\n",
    "        assert mode in [\"dense\",\"cosmargin\",\"arcmargin\"]\n",
    "        self.encoder=encoder\n",
    "        self.mode=mode\n",
    "        self.latent_features=encoder.latent_features\n",
    "        \n",
    "        if self.mode==\"dense\":\n",
    "            self.output_layer=keras.layers.Dense(out_features,use_bias=False)\n",
    "            self.loss_fn=FocalLoss(3)\n",
    "            return\n",
    "        \n",
    "        self.output_layer=CosineLayer(out_features)\n",
    "        if self.mode==\"cosmargin\":\n",
    "            self.loss_fn=AddMarginLoss(s=5,m=0.3)\n",
    "        if self.mode==\"arcmargin\":\n",
    "            self.loss_fn=ArcMarginLoss(s=5,m=0.4,easy_margin=False)\n",
    "        \n",
    "    def call(self,x,training=False):\n",
    "        latent=self.encoder(x)\n",
    "        return self.output_layer(latent)\n",
    "\n",
    "class SiameseModel(keras.Model):\n",
    "    # Mode: dist= euclidean distance\n",
    "    #       cos = cosine distance\n",
    "    #       matmult= matric multiplication distance\n",
    "    def __init__(self,encoder,mode=\"cos\"):\n",
    "        super().__init__()\n",
    "        assert mode in [\"dist\",\"cos\",\"matmul\"]\n",
    "        self.encoder=encoder\n",
    "        self.mode=mode\n",
    "        self.latent_features=encoder.latent_features\n",
    "        if self.mode==\"dist\":\n",
    "            self.matric_fn=EuclideanDist(\"paired\")\n",
    "        if self.mode==\"cos\":\n",
    "            self.matric_fn=CosSim(\"paired\")\n",
    "        if self.mode==\"matmul\":\n",
    "            self.matric_fn=MatMul(\"paired\")\n",
    "        self.loss_fn=ContrastiveLoss(1,mode=mode)\n",
    "            \n",
    "    def call(self,x,training=False):\n",
    "        latent_s=self.encoder(x[:,0])\n",
    "        latent_q=self.encoder(x[:,1])\n",
    "\n",
    "        return self.matric_fn(latent_q,latent_s)     \n",
    "  \n",
    "    \n",
    "class PrototypicalNetworks(keras.Model):\n",
    "    # Mode: dist= euclidean distance\n",
    "    #       cos = cosine distance\n",
    "    #       matmult= matric multiplication distance\n",
    "    def __init__(self,encoder,mode=\"cos\"):\n",
    "        super().__init__()\n",
    "        assert mode in [\"dist\",\"cos\",\"matmul\",\"cosmargin\",\"arcmargin\"]\n",
    "        self.encoder=encoder\n",
    "        self.mode=mode\n",
    "        self.latent_features=encoder.latent_features\n",
    "        #Metric function#    \n",
    "        if mode in [\"cos\",\"cosmargin\",\"arcmargin\"]:\n",
    "            self.matric_fn=CosSim(\"cross\")\n",
    "        if self.mode==\"dist\":\n",
    "            self.matric_fn=EuclideanDist(\"cross\")\n",
    "        if self.mode==\"matmul\":\n",
    "            self.matric_fn=MatMul(\"cross\")\n",
    "        #Loss function, including output activation#\n",
    "        if mode in [\"dist\",\"cos\",\"matmul\"]:\n",
    "            self.loss_fn=FocalLoss(3)\n",
    "        if self.mode==\"cosmargin\":\n",
    "            self.loss_fn=AddMarginLoss(s=5,m=0.3)\n",
    "        if self.mode==\"arcmargin\":\n",
    "            self.loss_fn=ArcMarginLoss(s=5,m=0.4,easy_margin=False)  \n",
    "            \n",
    "    def call(self,x,training=False):\n",
    "        # 計算query latent\n",
    "        latent_q=tf.stack([self.encoder(x[:,WAYS*SHOTS+ii]) for ii in range(WAYS)],axis=1)        \n",
    "        \n",
    "        # 計算 prototypes\n",
    "        latent_s=[self.encoder(x[:,ii]) for ii in range(WAYS*SHOTS)]\n",
    "        latent_proto=tf.stack([tf.reduce_mean(tf.stack(latent_s[ww*SHOTS:(ww+1)*SHOTS],axis=-1),axis=-1)\n",
    "                     for ww in range(WAYS)],axis=1)\n",
    "        # 計算metric\n",
    "        return self.matric_fn(latent_q,latent_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d840a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=Encoder(n_layers=2,latent_features=2,hidden_featrues=64)\n",
    "model=PrototypicalNetworks(enc,mode=\"arcmargin\")# {\"dist\",\"cos\",\"matmul\",\"cosmargin\",\"arcmargin\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96adce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn=ArcMarginLoss(s=5,m=0.4,easy_margin=False)\n",
    "loss_fn=model.loss_fn\n",
    "opt=keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=loss_fn, optimizer=opt, metrics=[keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "057aac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recording Callbacks\n",
    "class LogLatent(keras.callbacks.Callback):\n",
    "    def __init__(self,encoder,test_x,test_y,skip_iters=100):\n",
    "        self.df=self.df=pd.DataFrame()\n",
    "        self.encoder=encoder\n",
    "        self.plt_x=test_x\n",
    "        self.plt_y=test_y\n",
    "        self.itr=0\n",
    "        self.skip_iters=skip_iters\n",
    "    def on_batch_end(self,batch, logs={}):\n",
    "        if self.itr%self.skip_iters==self.skip_iters-1:\n",
    "            latent=self.encoder(self.plt_x)\n",
    "            df_new=pd.DataFrame()\n",
    "            df_new[\"f1\"]=latent[:,0]\n",
    "            df_new[\"f2\"]=latent[:,1]\n",
    "            df_new[\"arc\"]=0.5\n",
    "            df_new[\"iterations\"]=np.repeat(self.itr,len(latent))\n",
    "\n",
    "            df_new[\"label\"]=self.plt_y\n",
    "            self.df=self.df.append(df_new)\n",
    "        self.itr+=1\n",
    "    def normalize(self):\n",
    "        # Normalize latent by maximum value\n",
    "        self.mx_norm=np.linalg.norm(self.df[[\"f1\",\"f2\"]].values[-len(self.plt_y):],axis=1).max()\n",
    "        self.df[[\"f1\",'f2']]=self.df[[\"f1\",'f2']].apply(lambda x: x/self.mx_norm)\n",
    "\n",
    "        # Project latents into arc\n",
    "        df=self.df.copy()\n",
    "        norm=np.linalg.norm(df[[\"f1\",\"f2\"]].values,axis=1,keepdims=True)\n",
    "        df[[\"f1\",'f2']]=df[[\"f1\",'f2']].values/norm\n",
    "        df[\"arc\"]=df[\"arc\"].map({0.5:0.9},na_action=None)\n",
    "        \n",
    "        self.df=self.df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd0d92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = train_meta_loader.shuffle(1000).cache().prefetch(meta_batch_size).batch(meta_batch_size)\n",
    "\n",
    "val_loader = train_meta_loader.shuffle(1000).cache().prefetch(meta_batch_size*4).batch(meta_batch_size*4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47795d77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "19/19 [==============================] - 1358s 38s/step - loss: 1.8769 - categorical_accuracy: 0.3510 - val_loss: 1.2444 - val_categorical_accuracy: 0.5200\n",
      "Epoch 2/800\n",
      "19/19 [==============================] - 1s 56ms/step - loss: 1.2846 - categorical_accuracy: 0.4491 - val_loss: 1.2037 - val_categorical_accuracy: 0.5417\n",
      "Epoch 3/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 1.2103 - categorical_accuracy: 0.5112 - val_loss: 0.9320 - val_categorical_accuracy: 0.5777\n",
      "Epoch 4/800\n",
      "19/19 [==============================] - 1s 52ms/step - loss: 1.0122 - categorical_accuracy: 0.5252 - val_loss: 0.8174 - val_categorical_accuracy: 0.6133\n",
      "Epoch 5/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.8650 - categorical_accuracy: 0.5997 - val_loss: 0.7139 - val_categorical_accuracy: 0.6610\n",
      "Epoch 6/800\n",
      "19/19 [==============================] - 1s 56ms/step - loss: 0.7480 - categorical_accuracy: 0.6285 - val_loss: 0.5893 - val_categorical_accuracy: 0.7233\n",
      "Epoch 7/800\n",
      "19/19 [==============================] - 1s 55ms/step - loss: 0.6002 - categorical_accuracy: 0.7029 - val_loss: 0.5132 - val_categorical_accuracy: 0.7610\n",
      "Epoch 8/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.5834 - categorical_accuracy: 0.7175 - val_loss: 0.4403 - val_categorical_accuracy: 0.8023\n",
      "Epoch 9/800\n",
      "19/19 [==============================] - 1s 52ms/step - loss: 0.4856 - categorical_accuracy: 0.7519 - val_loss: 0.4416 - val_categorical_accuracy: 0.8043\n",
      "Epoch 10/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.4730 - categorical_accuracy: 0.7641 - val_loss: 0.4136 - val_categorical_accuracy: 0.8160\n",
      "Epoch 11/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.4752 - categorical_accuracy: 0.7761 - val_loss: 0.4559 - val_categorical_accuracy: 0.7903\n",
      "Epoch 12/800\n",
      "19/19 [==============================] - 1s 52ms/step - loss: 0.5416 - categorical_accuracy: 0.7521 - val_loss: 0.4046 - val_categorical_accuracy: 0.8193\n",
      "Epoch 13/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.4225 - categorical_accuracy: 0.7837 - val_loss: 0.3733 - val_categorical_accuracy: 0.8270\n",
      "Epoch 14/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.4085 - categorical_accuracy: 0.7993 - val_loss: 0.4012 - val_categorical_accuracy: 0.8313\n",
      "Epoch 15/800\n",
      "19/19 [==============================] - 1s 52ms/step - loss: 0.4451 - categorical_accuracy: 0.8011 - val_loss: 0.3635 - val_categorical_accuracy: 0.8260\n",
      "Epoch 16/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.3653 - categorical_accuracy: 0.8037 - val_loss: 0.3466 - val_categorical_accuracy: 0.8353\n",
      "Epoch 17/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.3646 - categorical_accuracy: 0.8055 - val_loss: 0.3252 - val_categorical_accuracy: 0.8513\n",
      "Epoch 18/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.3351 - categorical_accuracy: 0.8245 - val_loss: 0.3279 - val_categorical_accuracy: 0.8497\n",
      "Epoch 19/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.3173 - categorical_accuracy: 0.8230 - val_loss: 0.3105 - val_categorical_accuracy: 0.8557\n",
      "Epoch 20/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.3377 - categorical_accuracy: 0.8176 - val_loss: 0.4199 - val_categorical_accuracy: 0.8083\n",
      "Epoch 21/800\n",
      "19/19 [==============================] - 1s 52ms/step - loss: 0.5110 - categorical_accuracy: 0.7765 - val_loss: 0.3533 - val_categorical_accuracy: 0.8387\n",
      "Epoch 22/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.3587 - categorical_accuracy: 0.8064 - val_loss: 0.3551 - val_categorical_accuracy: 0.8397\n",
      "Epoch 23/800\n",
      "19/19 [==============================] - 1s 52ms/step - loss: 0.3282 - categorical_accuracy: 0.8247 - val_loss: 0.3398 - val_categorical_accuracy: 0.8403\n",
      "Epoch 24/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.3112 - categorical_accuracy: 0.8384 - val_loss: 0.3660 - val_categorical_accuracy: 0.8483\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 25/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.3504 - categorical_accuracy: 0.8329 - val_loss: 0.3074 - val_categorical_accuracy: 0.8530\n",
      "Epoch 26/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2835 - categorical_accuracy: 0.8504 - val_loss: 0.3037 - val_categorical_accuracy: 0.8543\n",
      "Epoch 27/800\n",
      "19/19 [==============================] - 1s 56ms/step - loss: 0.2957 - categorical_accuracy: 0.8418 - val_loss: 0.3028 - val_categorical_accuracy: 0.8570\n",
      "Epoch 28/800\n",
      "19/19 [==============================] - 1s 54ms/step - loss: 0.2742 - categorical_accuracy: 0.8573 - val_loss: 0.3016 - val_categorical_accuracy: 0.8550\n",
      "Epoch 29/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2852 - categorical_accuracy: 0.8453 - val_loss: 0.3000 - val_categorical_accuracy: 0.8573\n",
      "Epoch 30/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2836 - categorical_accuracy: 0.8589 - val_loss: 0.3013 - val_categorical_accuracy: 0.8600\n",
      "Epoch 31/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2702 - categorical_accuracy: 0.8598 - val_loss: 0.2986 - val_categorical_accuracy: 0.8603\n",
      "Epoch 32/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2806 - categorical_accuracy: 0.8546 - val_loss: 0.2983 - val_categorical_accuracy: 0.8593\n",
      "Epoch 33/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2700 - categorical_accuracy: 0.8577 - val_loss: 0.2965 - val_categorical_accuracy: 0.8620\n",
      "Epoch 34/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2641 - categorical_accuracy: 0.8585 - val_loss: 0.2959 - val_categorical_accuracy: 0.8620\n",
      "Epoch 35/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2690 - categorical_accuracy: 0.8582 - val_loss: 0.2987 - val_categorical_accuracy: 0.8630\n",
      "Epoch 36/800\n",
      "19/19 [==============================] - 1s 54ms/step - loss: 0.2824 - categorical_accuracy: 0.8576 - val_loss: 0.2972 - val_categorical_accuracy: 0.8603\n",
      "Epoch 37/800\n",
      "19/19 [==============================] - 1s 54ms/step - loss: 0.2613 - categorical_accuracy: 0.8711 - val_loss: 0.2993 - val_categorical_accuracy: 0.8603\n",
      "Epoch 38/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2668 - categorical_accuracy: 0.8532 - val_loss: 0.2946 - val_categorical_accuracy: 0.8617\n",
      "Epoch 39/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2644 - categorical_accuracy: 0.8612 - val_loss: 0.2942 - val_categorical_accuracy: 0.8643\n",
      "Epoch 40/800\n",
      "19/19 [==============================] - 1s 54ms/step - loss: 0.2668 - categorical_accuracy: 0.8607 - val_loss: 0.2933 - val_categorical_accuracy: 0.8647\n",
      "Epoch 41/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2586 - categorical_accuracy: 0.8650 - val_loss: 0.2934 - val_categorical_accuracy: 0.8627\n",
      "Epoch 42/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2592 - categorical_accuracy: 0.8549 - val_loss: 0.2919 - val_categorical_accuracy: 0.8650\n",
      "Epoch 43/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2530 - categorical_accuracy: 0.8747 - val_loss: 0.2900 - val_categorical_accuracy: 0.8673\n",
      "Epoch 44/800\n",
      "19/19 [==============================] - 1s 55ms/step - loss: 0.2560 - categorical_accuracy: 0.8640 - val_loss: 0.2940 - val_categorical_accuracy: 0.8663\n",
      "Epoch 45/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2707 - categorical_accuracy: 0.8676 - val_loss: 0.2911 - val_categorical_accuracy: 0.8697\n",
      "Epoch 46/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2535 - categorical_accuracy: 0.8681 - val_loss: 0.2873 - val_categorical_accuracy: 0.8693\n",
      "Epoch 47/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2507 - categorical_accuracy: 0.8712 - val_loss: 0.2853 - val_categorical_accuracy: 0.8700\n",
      "Epoch 48/800\n",
      "19/19 [==============================] - 1s 54ms/step - loss: 0.2453 - categorical_accuracy: 0.8600 - val_loss: 0.2840 - val_categorical_accuracy: 0.8697\n",
      "Epoch 49/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2587 - categorical_accuracy: 0.8637 - val_loss: 0.3154 - val_categorical_accuracy: 0.8770\n",
      "Epoch 50/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2670 - categorical_accuracy: 0.8711 - val_loss: 0.2889 - val_categorical_accuracy: 0.8733\n",
      "Epoch 51/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2474 - categorical_accuracy: 0.8624 - val_loss: 0.2929 - val_categorical_accuracy: 0.8747\n",
      "Epoch 52/800\n",
      "19/19 [==============================] - 1s 52ms/step - loss: 0.2465 - categorical_accuracy: 0.8733 - val_loss: 0.2840 - val_categorical_accuracy: 0.8743\n",
      "Epoch 53/800\n",
      "19/19 [==============================] - 1s 54ms/step - loss: 0.2379 - categorical_accuracy: 0.8711 - val_loss: 0.2887 - val_categorical_accuracy: 0.8760\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 54/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2484 - categorical_accuracy: 0.8661 - val_loss: 0.2888 - val_categorical_accuracy: 0.8760\n",
      "Epoch 55/800\n",
      "19/19 [==============================] - 1s 52ms/step - loss: 0.2460 - categorical_accuracy: 0.8741 - val_loss: 0.2886 - val_categorical_accuracy: 0.8760\n",
      "Epoch 56/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2473 - categorical_accuracy: 0.8620 - val_loss: 0.2887 - val_categorical_accuracy: 0.8757\n",
      "Epoch 57/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2361 - categorical_accuracy: 0.8820 - val_loss: 0.2886 - val_categorical_accuracy: 0.8757\n",
      "Epoch 58/800\n",
      "19/19 [==============================] - 1s 54ms/step - loss: 0.2430 - categorical_accuracy: 0.8721 - val_loss: 0.2874 - val_categorical_accuracy: 0.8763\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 59/800\n",
      "19/19 [==============================] - 1s 54ms/step - loss: 0.2418 - categorical_accuracy: 0.8687 - val_loss: 0.2872 - val_categorical_accuracy: 0.8763\n",
      "Epoch 60/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2551 - categorical_accuracy: 0.8695 - val_loss: 0.2872 - val_categorical_accuracy: 0.8763\n",
      "Epoch 61/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2318 - categorical_accuracy: 0.8834 - val_loss: 0.2872 - val_categorical_accuracy: 0.8763\n",
      "Epoch 62/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2418 - categorical_accuracy: 0.8665 - val_loss: 0.2872 - val_categorical_accuracy: 0.8763\n",
      "Epoch 63/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2471 - categorical_accuracy: 0.8739 - val_loss: 0.2872 - val_categorical_accuracy: 0.8767\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 64/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2498 - categorical_accuracy: 0.8709 - val_loss: 0.2872 - val_categorical_accuracy: 0.8767\n",
      "Epoch 65/800\n",
      "19/19 [==============================] - 1s 52ms/step - loss: 0.2578 - categorical_accuracy: 0.8671 - val_loss: 0.2872 - val_categorical_accuracy: 0.8767\n",
      "Epoch 66/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2474 - categorical_accuracy: 0.8726 - val_loss: 0.2872 - val_categorical_accuracy: 0.8767\n",
      "Epoch 67/800\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 0.2377 - categorical_accuracy: 0.8672 - val_loss: 0.2872 - val_categorical_accuracy: 0.8767\n",
      "Epoch 68/800\n",
      "19/19 [==============================] - 1s 54ms/step - loss: 0.2414 - categorical_accuracy: 0.8786 - val_loss: 0.2872 - val_categorical_accuracy: 0.8767\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00068: early stopping\n"
     ]
    }
   ],
   "source": [
    "lg=LogLatent(enc,plt_x,plt_y)\n",
    "reduce_lr = cb.ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=5, min_lr=1e-8, verbose=1)\n",
    "earlystop=cb.EarlyStopping(monitor='val_loss',patience=20,restore_best_weights=True, verbose=1)\n",
    "try:\n",
    "    model.fit(train_loader, \n",
    "              epochs=800,\n",
    "              validation_data=val_loader,\n",
    "              callbacks=[lg,reduce_lr,earlystop])\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50f37017",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f2313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig=px.scatter(lg.df, x=\"f1\", y=\"f2\", animation_frame=\"iterations\", color=\"label\",opacity=lg.df.arc,\n",
    "                range_x=[-1.5,1.5],\n",
    "              range_y=[-1.5,1.5])\n",
    "fig.update_yaxes(\n",
    "    scaleanchor = \"x\",\n",
    "    scaleratio = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e527e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"history/proto_arcmargin_tf.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9b53539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(10, 2) dtype=float32, numpy=\n",
       "array([[ 0.18704899,  0.02250218],\n",
       "       [ 0.12121026, -0.10678957],\n",
       "       [ 0.02535258,  0.24400404],\n",
       "       [-0.15941562,  0.19275862],\n",
       "       [-0.022591  , -0.22673993],\n",
       "       [-0.22677712,  0.07567718],\n",
       "       [ 0.15992527,  0.15428177],\n",
       "       [-0.11859933, -0.12187711],\n",
       "       [-0.17760316,  0.10250525],\n",
       "       [-0.16005751, -0.1558148 ]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inference=ClassModel(enc,mode=\"arcmargin\")# {\"dist\",\"cos\",\"matmul\",\"cosmargin\",\"arcmargin\"}\n",
    "opt=keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model_inference.compile(loss=loss_fn, optimizer=opt, metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "model_inference.build((None,28,28,1))\n",
    "def take_prototype(class_loader,encoder):\n",
    "    latent=[]\n",
    "    for loader in class_loader:\n",
    "        x,y=next(iter(loader.batch(20)))\n",
    "        latent.append(encoder(x))\n",
    "    return tf.reduce_mean(tf.stack(latent,axis=0),axis=1)\n",
    "proto=take_prototype(all_class_list,enc)\n",
    "model_inference.output_layer.weights[0].assign(proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb7e0499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.7114 - categorical_accuracy: 0.7250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.654492974281311, 0.7486000061035156]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inference.evaluate(x_test,y_test_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9d83798",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_finetune_loader = tf.data.Dataset.from_tensor_slices((x_train,y_train_1hot)).cache().shuffle(len(x_train)//2).batch(batch_size)\n",
    "val_finetune_loader = tf.data.Dataset.from_tensor_slices((x_val,y_val_1hot)).cache().shuffle(len(x_val)//2).batch(batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3cdfb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 5s 10ms/step - loss: 0.6885 - categorical_accuracy: 0.7538 - val_loss: 0.5536 - val_categorical_accuracy: 0.8406\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5600 - categorical_accuracy: 0.8357 - val_loss: 0.5089 - val_categorical_accuracy: 0.8633\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5199 - categorical_accuracy: 0.8613 - val_loss: 0.4311 - val_categorical_accuracy: 0.9054\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4887 - categorical_accuracy: 0.8738 - val_loss: 0.4166 - val_categorical_accuracy: 0.9107\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4512 - categorical_accuracy: 0.8907 - val_loss: 0.3956 - val_categorical_accuracy: 0.9212\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4526 - categorical_accuracy: 0.8913 - val_loss: 0.4266 - val_categorical_accuracy: 0.9107\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4391 - categorical_accuracy: 0.8965 - val_loss: 0.3806 - val_categorical_accuracy: 0.9284\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4192 - categorical_accuracy: 0.9052 - val_loss: 0.3669 - val_categorical_accuracy: 0.9298\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4045 - categorical_accuracy: 0.9100 - val_loss: 0.3849 - val_categorical_accuracy: 0.9237\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4057 - categorical_accuracy: 0.9109 - val_loss: 0.3620 - val_categorical_accuracy: 0.9323\n"
     ]
    }
   ],
   "source": [
    "lg=LogLatent(enc,plt_x,plt_y)\n",
    "try:\n",
    "    model_inference.fit(train_finetune_loader, \n",
    "              epochs=epochs,\n",
    "              validation_data=val_finetune_loader,\n",
    "              callbacks=[lg])\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3d399f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1561ae48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig=px.scatter(lg.df, x=\"f1\", y=\"f2\", animation_frame=\"iterations\", color=\"label\",opacity=lg.df.arc,\n",
    "                range_x=[-1.5,1.5],\n",
    "              range_y=[-1.5,1.5])\n",
    "fig.update_yaxes(\n",
    "    scaleanchor = \"x\",\n",
    "    scaleratio = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48279474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3438 - categorical_accuracy: 0.9372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3437580466270447, 0.9372000098228455]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inference.evaluate(x_test,y_test_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5a38903",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"history/proto_baseline_arcmargin_tf.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26df83b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
